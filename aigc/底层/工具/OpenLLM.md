# OpenLLM

用于在生产中操作大型语言模型(LLMs)的开放平台。轻松地微调、服务、部署和监控任何LLM。

使用OpenLLM，您可以使用任何开源的大型语言模型运行推理，部署到云或本地，并构建强大的AI应用程序。

最先进的llm:内置支持广泛的开源llm和模型运行时，包括StableLM, Falcon, Dolly, Flan-T5, ChatGLM, StarCoder等。

灵活的API:一条命令部署LLM的RESTful API或gRPC服务，查询通过web、CLI和我们的python/javascript
客户端或任何 httpClient.

自由构建:一流的支持LangChain, BentoML和HuggingFace，
通过模型和其它服务的LLMs组合轻松创建您的应用。

精简部署:自动生成您的LLM服务器Docker镜像或通过BentoCloud部署为无服务器站点。

自带LLM:使用LLM.tuning()对任何LLM进行微调以满足您的需求。

github: [https://github.com/bentoml/OpenLLM](https://github.com/bentoml/OpenLLM)