# Open-Llama

开源高性能Llama模型完整的训练代码，包括从预训练到RLHF的全过程。
即可以使用开源的[HuggingFace: s-JoL/Open-Llama-V2](https://huggingface.co/s-JoL/Open-Llama-V2)。
也可以自行训练。经过测试，在中文问题上能够达到GPT3.5's的89%的能力。
训练速度达到3620/s，快于原有的Llama论文3370 tokens/s，达到先进水平。

github: [https://github.com/s-JoL/Open-Llama](https://github.com/s-JoL/Open-Llama)