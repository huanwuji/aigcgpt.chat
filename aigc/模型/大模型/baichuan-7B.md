# baichuan-7B

baichuan-7B 是由百川智能开发的一个开源可商用的大规模预训练语言模型。基于 Transformer 结构，在大约 1.2 万亿 tokens 上训练的
70 亿参数模型，支持中英双语，上下文窗口长度为 4096。
在标准的中文和英文权威 benchmark（C-EVAL/MMLU）上均取得同尺寸最好的效果。

github: [https://github.com/baichuan-inc/baichuan-7B](https://github.com/baichuan-inc/baichuan-7B)